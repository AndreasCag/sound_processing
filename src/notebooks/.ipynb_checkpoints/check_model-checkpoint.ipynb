{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76cd3c6-9f52-44c5-96b4-42786a494d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cc42e2-b594-4791-b45c-05f8982d6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path2add = '/Users/a.anikin/repos/cv_court_lines_detection/sound_processing/src'\n",
    "if (not (path2add in sys.path)) :\n",
    "    sys.path.append(path2add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e53e10a-c0fc-40f4-9fb7-50c01a7e0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BreathingDataset\n",
    "from model import RawAudioCNN\n",
    "from train import train_model\n",
    "from augmentations import train_augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43f1312-522b-42ea-b887-73d09a1fa5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_data = RawAudioCNN.from_checkpoint('/Users/a.anikin/repos/cv_court_lines_detection/sound_processing/models/best_model_4_1.0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82cad23d-791b-424d-802a-259c826e7012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RawAudioCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (17): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): AdaptiveAvgPool1d(output_size=16)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_data['model']\n",
    "checkpoint_data['model'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0cde75-b106-41e9-9ba0-08ef4271f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d901ca-a174-4c2a-ac9d-100a3bd4c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.872"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform, rate = torchaudio.load('/Users/a.anikin/repos/cv_court_lines_detection/sound_processing/data/test/test.mp3')\n",
    "\n",
    "waveform.shape[1] / rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33d34041-2fc9-47df-b36f-6325211da923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77898402-8493-4790-ac88-5df23ca632e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(rate, model_rate)\n",
    "waveform = resampler(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05438964-e763-47a8-9bed-2ae93776a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.872"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape[1] / model_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "630994dd-b2f8-455d-a73a-293bd02ec838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bafec78c-0b00-42ce-a884-90ff8749d810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 413952])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e873123-e8d5-43e4-9d19-276d4cb6688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64000])\n",
      "tensor([[-2.0724,  3.0062]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1, 64000])\n",
      "tensor([[-1.6413,  2.5195]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1, 64000])\n",
      "tensor([[ 2.1656, -1.1675]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1, 64000])\n",
      "tensor([[-1.5157,  3.8721]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    waveform_part = waveform[:, i * model_rate: (i + model_audio_size) * model_rate].unsqueeze(0)\n",
    "    print(waveform_part.shape)\n",
    "\n",
    "    print(checkpoint_data['model'](waveform_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419986d-beed-4c8b-97b0-b535a088e2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
